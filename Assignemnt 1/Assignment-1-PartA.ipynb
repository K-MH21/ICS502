{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-1 (KNN Classifier)-Part-A\n",
    "## Handwritten digit recognition\n",
    "In this assignment part-A, we will use the built-in library ``sklearn`` to use KNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST dataset\n",
    "`MNIST` is a classic dataset in machine learning, consisting of 28x28 gray-scale images handwritten digits. The training set contains 60,000 examples and the test set contains 10,000 examples. In this assignment we will further split the training set to take out 12,000 examples as a validation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gzip, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that downloads a specified MNIST data file from Yann Le Cun's website\n",
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "# Invokes download() if necessary, then reads in images\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the training set\n",
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset dimensions:  (60000, 784)\n",
      "Number of training labels:  60000\n",
      "Testing dataset dimensions:  (10000, 784)\n",
      "Number of testing labels:  10000\n"
     ]
    }
   ],
   "source": [
    "## Print out their dimensions\n",
    "print(\"Training dataset dimensions: \", np.shape(train_data))\n",
    "print(\"Number of training labels: \", len(train_labels))\n",
    "print(\"Testing dataset dimensions: \", np.shape(test_data))\n",
    "print(\"Number of testing labels: \", len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set distribution:\n",
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "Test set distribution:\n",
      "{0: 980, 1: 1135, 2: 1032, 3: 1010, 4: 982, 5: 892, 6: 958, 7: 1028, 8: 974, 9: 1009}\n"
     ]
    }
   ],
   "source": [
    "## Compute the number of examples of each digit\n",
    "train_digits, train_counts = np.unique(train_labels, return_counts=True)\n",
    "print(\"Training set distribution:\")\n",
    "print(dict(zip(train_digits, train_counts)))\n",
    "\n",
    "test_digits, test_counts = np.unique(test_labels, return_counts=True)\n",
    "print(\"Test set distribution:\")\n",
    "print(dict(zip(test_digits, test_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 7\n"
     ]
    }
   ],
   "source": [
    "## Define a function that displays a digit given its vector representation\n",
    "def show_digit(x):\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x.reshape((28,28)), cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "## Define a function that takes an index into a particular data set (\"train\" or \"test\") and displays that image.\n",
    "def vis_image(index, dataset=\"train\"):\n",
    "    if(dataset==\"train\"): \n",
    "        show_digit(train_data[index,])\n",
    "        label = train_labels[index]\n",
    "    else:\n",
    "        show_digit(test_data[index,])\n",
    "        label = test_labels[index]\n",
    "    print(\"Label \" + str(label))\n",
    "    return\n",
    "\n",
    "## View the first data point in the training set\n",
    "vis_image(0, \"train\")\n",
    "\n",
    "## Now view the first data point in the test set\n",
    "vis_image(0, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Train data to Train and Validate Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainx, valx, trainy, valy = train_test_split(train_data, train_labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Nearest neighbor classifier--Brute Force Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the built-in KNN classifier to perform handwritten digit classification task. Please keep in mind that any hyper-parameter selection shall be performed on the independent validation set and not on the test set. You need to study the KNeighborsClassifier documentation to understand how to use the api with different parameters. In this set of experiments, you need to select 'brute' for the **algorithm** parameter. Record the error rates on the test set and the cpu time taken for evaluation.\n",
    "\n",
    "**Note:** Here you don't have to implement the KNN classifier but you just need to use it from ``sklearn`` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error rate: 2.849999999999997 \"%\n",
      "CPU time:  48.8053362  Seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "### START CODE HERE ###\n",
    "neigh = KNeighborsClassifier(algorithm='brute')\n",
    "neigh.fit(trainx, trainy)\n",
    "start_time = time.process_time()\n",
    "test_predection = neigh.predict(valx)\n",
    "cpu_time = time.process_time() - start_time\n",
    "test_error_rate = (1 - neigh.score(valx, valy)) * 100\n",
    "print(f'Test error rate: {test_error_rate} \"%')\n",
    "print(\"CPU time: \", cpu_time, \" Seconds\")\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Faster nearest neighbor methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing nearest neighbor classification in the way we have presented requires a full pass through the training set in order to classify a single point. If there are $N$ training points in $\\mathbb{R}^d$, this takes $O(N d)$ time.\n",
    "\n",
    "Fortunately, there are faster methods to perform nearest neighbor look up if we are willing to spend some time preprocessing the training set. `scikit-learn` has fast implementations of two useful nearest neighbor data structures: the _ball tree_ and the _k-d tree_. Record the error rates on the test set and the cpu time taken for evaluation using these two faster methods.\n",
    "\n",
    "**Note:** You need to select 'ball_tree'or 'kd_tree' for the **algorithm** parameter for ``KNeighborsClassifier`` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error rate with ball tree: 2.849999999999997 \"%\n",
      "CPU time with ball tree:  467.24019640000006  Seconds\n",
      "Test error rate with kd tree: 2.849999999999997 \"%\n",
      "CPU time with kd tree:  592.9134531  Seconds\n"
     ]
    }
   ],
   "source": [
    "# You can use KNeighborsClassifier with correct values for 'algorithm'\n",
    "### START CODE HERE ###\n",
    "neigh_ball = KNeighborsClassifier(algorithm='ball_tree')\n",
    "neigh_ball.fit(trainx, trainy)\n",
    "start_time = time.process_time()\n",
    "test_predection_ball = neigh_ball.predict(valx)\n",
    "cpu_time_ball = time.process_time() - start_time\n",
    "test_error_rate_ball = (1 - neigh_ball.score(valx, valy)) * 100\n",
    "print(f'Test error rate with ball tree: {test_error_rate_ball} \"%')\n",
    "print(\"CPU time with ball tree: \", cpu_time_ball, \" Seconds\")\n",
    "\n",
    "neigh_kd = KNeighborsClassifier(algorithm='kd_tree')\n",
    "neigh_kd.fit(trainx, trainy)\n",
    "start_time = time.process_time()\n",
    "test_predection_kd = neigh_kd.predict(valx)\n",
    "cpu_time_kd = time.process_time() - start_time\n",
    "test_error_rate_kd = (1 - neigh_kd.score(valx, valy)) * 100\n",
    "print(f'Test error rate with kd tree: {test_error_rate_kd} \"%')\n",
    "print(\"CPU time with kd tree: \", cpu_time_kd, \" Seconds\")\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Record CPU time and accuracy for all the three approaches in different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use brute-force, kd-tree, and ball-tree approaches for the following datasets and record the accuracies and cpu time (for evaluation step only). Looking at the results, can you explain it.\n",
    "\n",
    "Datasets:\n",
    "1. Abalone Data Set (https://archive.ics.uci.edu/ml/datasets/abalone)\n",
    "2. Statlog (Landsat Satellite) Data Set (https://archive.ics.uci.edu/ml/datasets/Statlog+(Landsat+Satellite))\n",
    "\n",
    "**Note:** The datasets are provided as attachement in the assignment as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone\n",
      "Test error rate with brute: 0.11961722488038617 \"%\n",
      "CPU time with brute:  0.05271629999970173  Seconds\n",
      "Test error rate with ball tree: 0.11961722488038617 \"%\n",
      "CPU time with ball tree:  0.043901500000174565  Seconds\n",
      "Test error rate with kd tree: 0.11961722488038617 \"%\n",
      "CPU time with kd tree:  0.03657669999984137  Seconds\n",
      "Statlog\n",
      "Test error rate with brute: 8.320373250388801 \"%\n",
      "CPU time with brute: 48.8053362 Seconds\n",
      "Test error rate with ball tree: 8.320373250388801 \"%\n",
      "CPU time with ball tree: 0.18358330000000933 Seconds\n",
      "Test error rate with kd tree: 8.320373250388801 \"%\n",
      "CPU time with kd tree: 0.17018469999993613 Seconds\n"
     ]
    }
   ],
   "source": [
    "# You can use KNeighborsClassifier with correct values for 'algorithm'\n",
    "### START CODE HERE ###\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "print(\"Abalone\")\n",
    "df = pd.read_csv('Abalone19.csv')\n",
    "one_hot_encoded = pd.get_dummies(df.iloc[:, 0], prefix='sex')\n",
    "df = pd.concat([df.drop(df.columns[0], axis=1), one_hot_encoded], axis=1)\n",
    "trainx, valx, trainy, valy = train_test_split(df.drop(df.columns[-1], axis=1), df[df.columns[-1]], test_size=0.20, random_state=42)\n",
    "\n",
    "neigh_brute = KNeighborsClassifier(algorithm='brute')\n",
    "neigh_brute.fit(trainx, trainy)\n",
    "start_time = time.process_time()\n",
    "test_predection_brute = neigh_brute.predict(valx)\n",
    "cpu_time_brute = time.process_time() - start_time\n",
    "test_error_rate_brute = (1 - neigh_brute.score(valx, valy)) * 100\n",
    "print(f'Test error rate with brute: {test_error_rate_brute} \"%')\n",
    "print(\"CPU time with brute: \", cpu_time_brute, \" Seconds\")\n",
    "\n",
    "neigh_ball = KNeighborsClassifier(algorithm='ball_tree')\n",
    "neigh_ball.fit(trainx, trainy)\n",
    "start_time = time.process_time()\n",
    "test_predection_ball = neigh_ball.predict(valx)\n",
    "cpu_time_ball = time.process_time() - start_time\n",
    "test_error_rate_ball = (1 - neigh_ball.score(valx, valy)) * 100\n",
    "print(f'Test error rate with ball tree: {test_error_rate_ball} \"%')\n",
    "print(\"CPU time with ball tree: \", cpu_time_ball, \" Seconds\")\n",
    "\n",
    "neigh_kd = KNeighborsClassifier(algorithm='kd_tree')\n",
    "neigh_kd.fit(trainx, trainy)\n",
    "start_time = time.process_time()\n",
    "test_predection_kd = neigh_kd.predict(valx)\n",
    "cpu_time_kd = time.process_time() - start_time\n",
    "test_error_rate_kd = (1 - neigh_kd.score(valx, valy)) * 100\n",
    "print(f'Test error rate with kd tree: {test_error_rate_kd} \"%')\n",
    "print(\"CPU time with kd tree: \", cpu_time_kd, \" Seconds\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Statlog\")\n",
    "\n",
    "df = pd.read_csv('186_satimage.csv')\n",
    "trainx, valx, trainy, valy = train_test_split(df.drop(df.columns[-1], axis=1), df[df.columns[-1]], test_size=0.20, random_state=42)\n",
    "\n",
    "neigh_brute = KNeighborsClassifier(algorithm='brute')\n",
    "neigh_brute.fit(trainx, trainy)\n",
    "start_time = time.process_time()\n",
    "test_predection_brute = neigh_brute.predict(valx)\n",
    "cpu_time_brute = time.process_time() - start_time\n",
    "test_error_rate_brute = (1 - neigh_brute.score(valx, valy)) * 100\n",
    "print(f'Test error rate with brute: {test_error_rate_brute} \"%')\n",
    "print(\"CPU time with brute:\", cpu_time, \"Seconds\")\n",
    "\n",
    "neigh_ball = KNeighborsClassifier(algorithm='ball_tree')\n",
    "neigh_ball.fit(trainx, trainy)\n",
    "start_time = time.process_time()\n",
    "test_predection_ball = neigh_ball.predict(valx)\n",
    "cpu_time_ball = time.process_time() - start_time\n",
    "test_error_rate_ball = (1 - neigh_ball.score(valx, valy)) * 100\n",
    "print(f'Test error rate with ball tree: {test_error_rate_ball} \"%')\n",
    "print(\"CPU time with ball tree:\", cpu_time_ball, \"Seconds\")\n",
    "\n",
    "neigh_kd = KNeighborsClassifier(algorithm='kd_tree')\n",
    "neigh_kd.fit(trainx, trainy)\n",
    "start_time = time.process_time()\n",
    "test_predection_kd = neigh_kd.predict(valx)\n",
    "cpu_time_kd = time.process_time() - start_time\n",
    "test_error_rate_kd = (1 - neigh_kd.score(valx, valy)) * 100\n",
    "print(f'Test error rate with kd tree: {test_error_rate_kd} \"%')\n",
    "print(\"CPU time with kd tree:\", cpu_time_kd, \"Seconds\")\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E1. Extra Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are invited to try some more ideas as extra work like:\n",
    "1. Instead of using the pixels as features, implement your own features (example: what were presented in the slides) and use them for KNN. You need to keep in mind that if you compute features which have different scales then it is important to scale/normalize the features (discussed in the slides)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points to remember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to keep in mind the following points:\n",
    "1. Use numpy arrays and numpy libraries for efficient computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
